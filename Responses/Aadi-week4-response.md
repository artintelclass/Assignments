These articles provided an interesting perspective on AI systems. While the media tends to highlight the incredible advances made by these AI systems, it is also important to remember that these systems are, in certain ways, incredibly simple. Biases that exist in the data used to train these systems will also be reflected in the results. While the articles did make it seem as if this was a new problem, it is, debatebly, a problem that statisticians, experimental scientists, and social science researchers have had to deal with for a long time. As these AI systems operate at the intersection of many of these different fields, it makes sense that some of the challenges in other fields are also inherited. It is also detable as to how effective the measures taken to reduce bias in these systems will actually be. While it may seem that eliminating bias by training the algorithm on what is 'good' and 'bad' would be effective, it is simply introducing the bias of the humans who are devising these new training sets into the algorithm. This may not, in most cases, be something that most people would object to - for example, removing biased correlations such as 'man is to doctor as woman is to nurse'. However, this could be more difficult in situations where we may not know if it is actually bias or fact. For example, perhaps an AI system that analyzes job applications rejects all applications from developing countries. Is this an undesired bias reflected from the data set, since the hirers from the data set disliked people from these countries, or is it an actual fact that people from these countries were underperforming, which is why the algorithm refused to hire them? Thus, while removing bias from AI system is a noteworthy goal, it may not actually be possible to achieve if humans are designing the training.
