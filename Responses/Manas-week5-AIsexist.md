The articles were very interesting. I found it amusing that how humans have tranfered their own racist/sexist ideas to the machines they are creating as well. It is very unfortunate to see the development of these AI machines. 
However, unlike humans we in a way know the root cause of these racist AI machines. It is because we are not training them in the right way using the right training material. It was mentioned in the articles that unlike humans, AI does not have the moral filter that we do and thus even if we train the AI on the wrong training material, the AI wont know what is the right thing to say. There were examples of how AIs based on natural language processing were using foul/racist words towards minorities and women. 
This is actually a very serious problem because AI is being used in a lot of industries that majorly impact the lives of people. Considering the fact that AI is involved in finance, healthcare etc. the consequences of faulty and biased AI can be severe. A racist AI, for instance, may decide that a person from a minority does not deserve to qualify for a loan.
However, it was aknowledged in the article that AI is like a blackbox. You train it on the data but then you dont know how it comes up with the result. It ais like a 'black box'.
