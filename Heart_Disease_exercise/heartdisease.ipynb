{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2)                 30        \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 303 samples, validate on 303 samples\n",
      "Epoch 1/10\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.2657 - acc: 0.4686 - val_loss: 0.2502 - val_acc: 0.4620\n",
      "Epoch 2/10\n",
      "303/303 [==============================] - 0s 252us/step - loss: 0.2480 - acc: 0.5446 - val_loss: 0.2467 - val_acc: 0.5908\n",
      "Epoch 3/10\n",
      "303/303 [==============================] - 0s 355us/step - loss: 0.2481 - acc: 0.5479 - val_loss: 0.2432 - val_acc: 0.6502\n",
      "Epoch 4/10\n",
      "303/303 [==============================] - 0s 368us/step - loss: 0.2497 - acc: 0.5446 - val_loss: 0.2485 - val_acc: 0.5413\n",
      "Epoch 5/10\n",
      "303/303 [==============================] - 0s 484us/step - loss: 0.2488 - acc: 0.5578 - val_loss: 0.2470 - val_acc: 0.5842\n",
      "Epoch 6/10\n",
      "303/303 [==============================] - 0s 195us/step - loss: 0.2484 - acc: 0.5677 - val_loss: 0.2466 - val_acc: 0.5644\n",
      "Epoch 7/10\n",
      "303/303 [==============================] - 0s 404us/step - loss: 0.2470 - acc: 0.5875 - val_loss: 0.2459 - val_acc: 0.5809\n",
      "Epoch 8/10\n",
      "303/303 [==============================] - 0s 220us/step - loss: 0.2485 - acc: 0.5479 - val_loss: 0.2434 - val_acc: 0.6139\n",
      "Epoch 9/10\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.2486 - acc: 0.5578 - val_loss: 0.2426 - val_acc: 0.6040\n",
      "Epoch 10/10\n",
      "303/303 [==============================] - 0s 342us/step - loss: 0.2425 - acc: 0.6007 - val_loss: 0.2522 - val_acc: 0.4785\n",
      "Test loss: 0.2522187170022392\n",
      "Test accuracy: 0.47854785557233853\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.contrib.keras as keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 10\n",
    "num_classes = 2\n",
    "epochs = 10\n",
    "num_input_nodes = 13\n",
    "num_hidden_nodes = 15\n",
    "learning_rate = 0.1\n",
    "\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "training_data = pd.read_csv(\"processed.cleveland.data.csv\", header=None, index_col=False)\n",
    "\n",
    "# take the first column and store as labels as numpy array\n",
    "training_labels = np.asfarray(training_data.iloc[:,13])\n",
    "training_labels= np.clip(training_labels,0,1)\n",
    "\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "x_train = np.asfarray(training.drop(columns=[13]))\n",
    "\n",
    "# use pandas to read file\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "test = pd.read_csv(\"processed.cleveland.data.csv\", header=None, index_col=False)\n",
    "\n",
    "# take the first column and store as labels as numpy array\n",
    "test_labels = np.asfarray(test.iloc[:,13])\n",
    "test_labels= np.clip(test_labels,0,1)\n",
    "\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "x_test = np.asfarray(test.drop(columns=[13]))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(training_labels, num_classes)\n",
    "y_test = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential() # means we have layers that are stacked on each other in sequence\n",
    "model.add(Dense(num_hidden_nodes, activation='sigmoid', input_shape=(num_input_nodes,), use_bias=False))\n",
    "model.add(Dense(num_classes, activation='sigmoid', use_bias=False))\n",
    "\n",
    "model.summary() # prints out a representation of the model\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=SGD(lr=learning_rate),#'RMSProp',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    shuffle=False)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
