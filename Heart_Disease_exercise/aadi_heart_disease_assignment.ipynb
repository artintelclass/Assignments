{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.optimizers\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'cleveland.data'\n",
    "batch_size = 10\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "num_input_nodes = 12\n",
    "num_hidden_nodes = 200\n",
    "learning_rate = 0.01\n",
    "test_fraction = 0.9\n",
    "\n",
    "rows = 302\n",
    "cols = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_file, header=None)\n",
    "\n",
    "train_rows = int(rows*test_fraction)\n",
    "test_rows = rows-train_rows+1 if(rows*test_fraction > train_rows) else rows-train_rows\n",
    "\n",
    "x_train = np.zeros([train_rows,cols-1])\n",
    "x_test = np.zeros([test_rows,cols-1])\n",
    "\n",
    "for col in range(cols-1):\n",
    "    for row in range(train_rows):\n",
    "        x_train[row][col] = df[col][row]\n",
    "\n",
    "for col in range(cols-1):\n",
    "    for row in range(train_rows, rows):\n",
    "        x_test[row-train_rows][col] = df[col][row]\n",
    "\n",
    "y_train = np.zeros([train_rows])\n",
    "y_test = np.zeros([test_rows])\n",
    "\n",
    "for row in range(train_rows):\n",
    "    y_train[row-train_rows] = 1 if(int(df[13][row]) > 0) else 0\n",
    "    #y_train[row] = int(df[13][row])\n",
    "\n",
    "for row in range(train_rows, rows):\n",
    "    y_test[row-train_rows] = 1 if(int(df[13][row]) > 0) else 0\n",
    "    #y_test[row-train_rows] = int(df[13][row])\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1451 (Dense)           (None, 200)               2400      \n",
      "_________________________________________________________________\n",
      "dense_1452 (Dense)           (None, 2)                 400       \n",
      "=================================================================\n",
      "Total params: 2,800\n",
      "Trainable params: 2,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 271 samples, validate on 32 samples\n",
      "Epoch 1/100\n",
      "271/271 [==============================] - 5s 17ms/step - loss: 0.2351 - acc: 0.5793 - val_loss: 0.2266 - val_acc: 0.6562\n",
      "Epoch 2/100\n",
      "271/271 [==============================] - 0s 550us/step - loss: 0.2206 - acc: 0.6458 - val_loss: 0.2145 - val_acc: 0.6250\n",
      "Epoch 3/100\n",
      "271/271 [==============================] - 0s 589us/step - loss: 0.2131 - acc: 0.6679 - val_loss: 0.2100 - val_acc: 0.6562\n",
      "Epoch 4/100\n",
      "271/271 [==============================] - 0s 556us/step - loss: 0.2086 - acc: 0.6863 - val_loss: 0.2065 - val_acc: 0.6562\n",
      "Epoch 5/100\n",
      "271/271 [==============================] - 0s 552us/step - loss: 0.2048 - acc: 0.6827 - val_loss: 0.2037 - val_acc: 0.6875\n",
      "Epoch 6/100\n",
      "271/271 [==============================] - 0s 585us/step - loss: 0.2016 - acc: 0.6974 - val_loss: 0.2013 - val_acc: 0.6875\n",
      "Epoch 7/100\n",
      "271/271 [==============================] - 0s 553us/step - loss: 0.1984 - acc: 0.6974 - val_loss: 0.2015 - val_acc: 0.6875\n",
      "Epoch 8/100\n",
      "271/271 [==============================] - 0s 560us/step - loss: 0.1962 - acc: 0.7011 - val_loss: 0.2002 - val_acc: 0.6875\n",
      "Epoch 9/100\n",
      "271/271 [==============================] - 0s 684us/step - loss: 0.1932 - acc: 0.7085 - val_loss: 0.1991 - val_acc: 0.7187\n",
      "Epoch 10/100\n",
      "271/271 [==============================] - 0s 609us/step - loss: 0.1910 - acc: 0.7085 - val_loss: 0.1979 - val_acc: 0.7187\n",
      "Epoch 11/100\n",
      "271/271 [==============================] - 0s 625us/step - loss: 0.1885 - acc: 0.7159 - val_loss: 0.1978 - val_acc: 0.6875\n",
      "Epoch 12/100\n",
      "271/271 [==============================] - 0s 622us/step - loss: 0.1864 - acc: 0.7159 - val_loss: 0.1968 - val_acc: 0.6875\n",
      "Epoch 13/100\n",
      "271/271 [==============================] - 0s 603us/step - loss: 0.1842 - acc: 0.7159 - val_loss: 0.1955 - val_acc: 0.6875\n",
      "Epoch 14/100\n",
      "271/271 [==============================] - 0s 593us/step - loss: 0.1820 - acc: 0.7232 - val_loss: 0.1944 - val_acc: 0.6563\n",
      "Epoch 15/100\n",
      "271/271 [==============================] - 0s 614us/step - loss: 0.1801 - acc: 0.7269 - val_loss: 0.1915 - val_acc: 0.6875\n",
      "Epoch 16/100\n",
      "271/271 [==============================] - 0s 578us/step - loss: 0.1777 - acc: 0.7380 - val_loss: 0.1912 - val_acc: 0.6875\n",
      "Epoch 17/100\n",
      "271/271 [==============================] - 0s 653us/step - loss: 0.1759 - acc: 0.7343 - val_loss: 0.1893 - val_acc: 0.6875\n",
      "Epoch 18/100\n",
      "271/271 [==============================] - 0s 600us/step - loss: 0.1734 - acc: 0.7380 - val_loss: 0.1871 - val_acc: 0.6875\n",
      "Epoch 19/100\n",
      "271/271 [==============================] - 0s 596us/step - loss: 0.1714 - acc: 0.7417 - val_loss: 0.1869 - val_acc: 0.6875\n",
      "Epoch 20/100\n",
      "271/271 [==============================] - 0s 607us/step - loss: 0.1693 - acc: 0.7491 - val_loss: 0.1840 - val_acc: 0.6562\n",
      "Epoch 21/100\n",
      "271/271 [==============================] - 0s 625us/step - loss: 0.1668 - acc: 0.7491 - val_loss: 0.1826 - val_acc: 0.6875\n",
      "Epoch 22/100\n",
      "271/271 [==============================] - 0s 630us/step - loss: 0.1651 - acc: 0.7638 - val_loss: 0.1799 - val_acc: 0.6875\n",
      "Epoch 23/100\n",
      "271/271 [==============================] - 0s 705us/step - loss: 0.1631 - acc: 0.7601 - val_loss: 0.1793 - val_acc: 0.6875\n",
      "Epoch 24/100\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1612 - acc: 0.7601 - val_loss: 0.1778 - val_acc: 0.6875\n",
      "Epoch 25/100\n",
      "271/271 [==============================] - 0s 704us/step - loss: 0.1590 - acc: 0.7565 - val_loss: 0.1757 - val_acc: 0.6562\n",
      "Epoch 26/100\n",
      "271/271 [==============================] - 0s 622us/step - loss: 0.1574 - acc: 0.7565 - val_loss: 0.1732 - val_acc: 0.6562\n",
      "Epoch 27/100\n",
      "271/271 [==============================] - 0s 598us/step - loss: 0.1552 - acc: 0.7565 - val_loss: 0.1722 - val_acc: 0.6562\n",
      "Epoch 28/100\n",
      "271/271 [==============================] - 0s 605us/step - loss: 0.1538 - acc: 0.7638 - val_loss: 0.1695 - val_acc: 0.6875\n",
      "Epoch 29/100\n",
      "271/271 [==============================] - 0s 619us/step - loss: 0.1525 - acc: 0.7786 - val_loss: 0.1691 - val_acc: 0.7187\n",
      "Epoch 30/100\n",
      "271/271 [==============================] - 0s 720us/step - loss: 0.1509 - acc: 0.7860 - val_loss: 0.1659 - val_acc: 0.7187\n",
      "Epoch 31/100\n",
      "271/271 [==============================] - 0s 752us/step - loss: 0.1492 - acc: 0.7897 - val_loss: 0.1659 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "271/271 [==============================] - 0s 786us/step - loss: 0.1475 - acc: 0.8044 - val_loss: 0.1622 - val_acc: 0.7187\n",
      "Epoch 33/100\n",
      "271/271 [==============================] - 0s 692us/step - loss: 0.1471 - acc: 0.8007 - val_loss: 0.1610 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "271/271 [==============================] - 0s 613us/step - loss: 0.1454 - acc: 0.8155 - val_loss: 0.1592 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "271/271 [==============================] - 0s 611us/step - loss: 0.1447 - acc: 0.8118 - val_loss: 0.1576 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "271/271 [==============================] - 0s 623us/step - loss: 0.1427 - acc: 0.8192 - val_loss: 0.1557 - val_acc: 0.7187\n",
      "Epoch 37/100\n",
      "271/271 [==============================] - 0s 599us/step - loss: 0.1423 - acc: 0.8229 - val_loss: 0.1543 - val_acc: 0.7187\n",
      "Epoch 38/100\n",
      "271/271 [==============================] - 0s 612us/step - loss: 0.1404 - acc: 0.8229 - val_loss: 0.1525 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1400 - acc: 0.8229 - val_loss: 0.1509 - val_acc: 0.7813\n",
      "Epoch 40/100\n",
      "271/271 [==============================] - 0s 753us/step - loss: 0.1384 - acc: 0.8339 - val_loss: 0.1491 - val_acc: 0.7813\n",
      "Epoch 41/100\n",
      "271/271 [==============================] - 0s 814us/step - loss: 0.1379 - acc: 0.8266 - val_loss: 0.1477 - val_acc: 0.7813\n",
      "Epoch 42/100\n",
      "271/271 [==============================] - 0s 745us/step - loss: 0.1369 - acc: 0.8303 - val_loss: 0.1459 - val_acc: 0.7813\n",
      "Epoch 43/100\n",
      "271/271 [==============================] - 0s 856us/step - loss: 0.1360 - acc: 0.8229 - val_loss: 0.1451 - val_acc: 0.7813\n",
      "Epoch 44/100\n",
      "271/271 [==============================] - 0s 734us/step - loss: 0.1354 - acc: 0.8266 - val_loss: 0.1428 - val_acc: 0.7813\n",
      "Epoch 45/100\n",
      "271/271 [==============================] - 0s 693us/step - loss: 0.1342 - acc: 0.8229 - val_loss: 0.1432 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      "271/271 [==============================] - 0s 710us/step - loss: 0.1340 - acc: 0.8266 - val_loss: 0.1403 - val_acc: 0.7813\n",
      "Epoch 47/100\n",
      "271/271 [==============================] - 0s 810us/step - loss: 0.1324 - acc: 0.8229 - val_loss: 0.1416 - val_acc: 0.7500\n",
      "Epoch 48/100\n",
      "271/271 [==============================] - 0s 787us/step - loss: 0.1327 - acc: 0.8339 - val_loss: 0.1387 - val_acc: 0.7812\n",
      "Epoch 49/100\n",
      "271/271 [==============================] - 0s 678us/step - loss: 0.1309 - acc: 0.8266 - val_loss: 0.1404 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      "271/271 [==============================] - 0s 661us/step - loss: 0.1313 - acc: 0.8303 - val_loss: 0.1374 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "271/271 [==============================] - 0s 668us/step - loss: 0.1296 - acc: 0.8303 - val_loss: 0.1394 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "271/271 [==============================] - 0s 689us/step - loss: 0.1300 - acc: 0.8303 - val_loss: 0.1363 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "271/271 [==============================] - 0s 817us/step - loss: 0.1284 - acc: 0.8303 - val_loss: 0.1387 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "271/271 [==============================] - 0s 701us/step - loss: 0.1288 - acc: 0.8303 - val_loss: 0.1354 - val_acc: 0.7812\n",
      "Epoch 55/100\n",
      "271/271 [==============================] - 0s 785us/step - loss: 0.1273 - acc: 0.8303 - val_loss: 0.1385 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "271/271 [==============================] - 0s 688us/step - loss: 0.1279 - acc: 0.8266 - val_loss: 0.1354 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "271/271 [==============================] - 0s 606us/step - loss: 0.1272 - acc: 0.8339 - val_loss: 0.1374 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      "271/271 [==============================] - 0s 567us/step - loss: 0.1269 - acc: 0.8339 - val_loss: 0.1343 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "271/271 [==============================] - 0s 605us/step - loss: 0.1256 - acc: 0.8303 - val_loss: 0.1371 - val_acc: 0.7500\n",
      "Epoch 60/100\n",
      "271/271 [==============================] - 0s 590us/step - loss: 0.1262 - acc: 0.8339 - val_loss: 0.1338 - val_acc: 0.7500\n",
      "Epoch 61/100\n",
      "271/271 [==============================] - 0s 585us/step - loss: 0.1249 - acc: 0.8303 - val_loss: 0.1364 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      "271/271 [==============================] - 0s 582us/step - loss: 0.1255 - acc: 0.8339 - val_loss: 0.1330 - val_acc: 0.7500\n",
      "Epoch 63/100\n",
      "271/271 [==============================] - 0s 591us/step - loss: 0.1243 - acc: 0.8303 - val_loss: 0.1356 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      "271/271 [==============================] - 0s 596us/step - loss: 0.1247 - acc: 0.8339 - val_loss: 0.1322 - val_acc: 0.7500\n",
      "Epoch 65/100\n",
      "271/271 [==============================] - 0s 635us/step - loss: 0.1237 - acc: 0.8303 - val_loss: 0.1347 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      "271/271 [==============================] - 0s 640us/step - loss: 0.1241 - acc: 0.8339 - val_loss: 0.1313 - val_acc: 0.7812\n",
      "Epoch 67/100\n",
      "271/271 [==============================] - 0s 575us/step - loss: 0.1230 - acc: 0.8339 - val_loss: 0.1338 - val_acc: 0.7812\n",
      "Epoch 68/100\n",
      "271/271 [==============================] - 0s 598us/step - loss: 0.1235 - acc: 0.8303 - val_loss: 0.1303 - val_acc: 0.7812\n",
      "Epoch 69/100\n",
      "271/271 [==============================] - 0s 621us/step - loss: 0.1223 - acc: 0.8376 - val_loss: 0.1328 - val_acc: 0.8125\n",
      "Epoch 70/100\n",
      "271/271 [==============================] - 0s 640us/step - loss: 0.1230 - acc: 0.8339 - val_loss: 0.1295 - val_acc: 0.8125\n",
      "Epoch 71/100\n",
      "271/271 [==============================] - 0s 615us/step - loss: 0.1218 - acc: 0.8339 - val_loss: 0.1321 - val_acc: 0.8437\n",
      "Epoch 72/100\n",
      "271/271 [==============================] - 0s 607us/step - loss: 0.1226 - acc: 0.8376 - val_loss: 0.1278 - val_acc: 0.8437\n",
      "Epoch 73/100\n",
      "271/271 [==============================] - 0s 596us/step - loss: 0.1209 - acc: 0.8376 - val_loss: 0.1317 - val_acc: 0.8437\n",
      "Epoch 74/100\n",
      "271/271 [==============================] - 0s 599us/step - loss: 0.1222 - acc: 0.8339 - val_loss: 0.1271 - val_acc: 0.8750\n",
      "Epoch 75/100\n",
      "271/271 [==============================] - 0s 604us/step - loss: 0.1208 - acc: 0.8376 - val_loss: 0.1315 - val_acc: 0.8750\n",
      "Epoch 76/100\n",
      "271/271 [==============================] - 0s 728us/step - loss: 0.1216 - acc: 0.8266 - val_loss: 0.1263 - val_acc: 0.8750\n",
      "Epoch 77/100\n",
      "271/271 [==============================] - 0s 734us/step - loss: 0.1200 - acc: 0.8413 - val_loss: 0.1304 - val_acc: 0.8750\n",
      "Epoch 78/100\n",
      "271/271 [==============================] - 0s 635us/step - loss: 0.1208 - acc: 0.8266 - val_loss: 0.1253 - val_acc: 0.8750\n",
      "Epoch 79/100\n",
      "271/271 [==============================] - 0s 611us/step - loss: 0.1194 - acc: 0.8413 - val_loss: 0.1297 - val_acc: 0.8750\n",
      "Epoch 80/100\n",
      "271/271 [==============================] - 0s 618us/step - loss: 0.1204 - acc: 0.8266 - val_loss: 0.1247 - val_acc: 0.8750\n",
      "Epoch 81/100\n",
      "271/271 [==============================] - 0s 669us/step - loss: 0.1190 - acc: 0.8376 - val_loss: 0.1286 - val_acc: 0.8750\n",
      "Epoch 82/100\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.1199 - acc: 0.8229 - val_loss: 0.1249 - val_acc: 0.8750\n",
      "Epoch 83/100\n",
      "271/271 [==============================] - 0s 664us/step - loss: 0.1186 - acc: 0.8339 - val_loss: 0.1274 - val_acc: 0.8750\n",
      "Epoch 84/100\n",
      "271/271 [==============================] - 0s 719us/step - loss: 0.1190 - acc: 0.8266 - val_loss: 0.1243 - val_acc: 0.8750\n",
      "Epoch 85/100\n",
      "271/271 [==============================] - 0s 766us/step - loss: 0.1179 - acc: 0.8339 - val_loss: 0.1268 - val_acc: 0.8750\n",
      "Epoch 86/100\n",
      "271/271 [==============================] - 0s 763us/step - loss: 0.1189 - acc: 0.8229 - val_loss: 0.1235 - val_acc: 0.8750\n",
      "Epoch 87/100\n",
      "271/271 [==============================] - 0s 748us/step - loss: 0.1175 - acc: 0.8339 - val_loss: 0.1267 - val_acc: 0.8750\n",
      "Epoch 88/100\n",
      "271/271 [==============================] - 0s 789us/step - loss: 0.1186 - acc: 0.8229 - val_loss: 0.1231 - val_acc: 0.9062\n",
      "Epoch 89/100\n",
      "271/271 [==============================] - 0s 807us/step - loss: 0.1169 - acc: 0.8339 - val_loss: 0.1263 - val_acc: 0.8750\n",
      "Epoch 90/100\n",
      "271/271 [==============================] - 0s 845us/step - loss: 0.1179 - acc: 0.8229 - val_loss: 0.1232 - val_acc: 0.9062\n",
      "Epoch 91/100\n",
      "271/271 [==============================] - 0s 719us/step - loss: 0.1164 - acc: 0.8339 - val_loss: 0.1262 - val_acc: 0.8750\n",
      "Epoch 92/100\n",
      "271/271 [==============================] - 0s 768us/step - loss: 0.1178 - acc: 0.8229 - val_loss: 0.1225 - val_acc: 0.8437\n",
      "Epoch 93/100\n",
      "271/271 [==============================] - 0s 728us/step - loss: 0.1160 - acc: 0.8413 - val_loss: 0.1265 - val_acc: 0.8750\n",
      "Epoch 94/100\n",
      "271/271 [==============================] - 0s 737us/step - loss: 0.1174 - acc: 0.8303 - val_loss: 0.1221 - val_acc: 0.8437\n",
      "Epoch 95/100\n",
      "271/271 [==============================] - 0s 749us/step - loss: 0.1155 - acc: 0.8413 - val_loss: 0.1265 - val_acc: 0.8750\n",
      "Epoch 96/100\n",
      "271/271 [==============================] - 0s 738us/step - loss: 0.1172 - acc: 0.8339 - val_loss: 0.1220 - val_acc: 0.8437\n",
      "Epoch 97/100\n",
      "271/271 [==============================] - 0s 815us/step - loss: 0.1152 - acc: 0.8450 - val_loss: 0.1274 - val_acc: 0.9062\n",
      "Epoch 98/100\n",
      "271/271 [==============================] - 0s 808us/step - loss: 0.1167 - acc: 0.8339 - val_loss: 0.1220 - val_acc: 0.8437\n",
      "Epoch 99/100\n",
      "271/271 [==============================] - 0s 740us/step - loss: 0.1146 - acc: 0.8450 - val_loss: 0.1272 - val_acc: 0.8750\n",
      "Epoch 100/100\n",
      "271/271 [==============================] - 0s 780us/step - loss: 0.1161 - acc: 0.8339 - val_loss: 0.1219 - val_acc: 0.8437\n",
      "Test loss: 0.12189499288797379\n",
      "Test accuracy: 0.84375\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # means we have layers that are stacked on each other in sequence\n",
    "model.add(Dense(num_hidden_nodes, activation='sigmoid', input_shape=(num_input_nodes,), use_bias=False))\n",
    "model.add(Dense(num_classes, activation='sigmoid', use_bias=False))\n",
    "    \n",
    "model.summary() # prints out a representation of the model\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Nadam(),#'RMSProp',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    shuffle=False)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
