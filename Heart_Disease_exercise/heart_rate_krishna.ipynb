{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was able to get about 82.6 percent accuracy. \n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.keras as keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.optimizers import Adam\n",
    "import csv \n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "file = '/Users/sreenivasanlab/Desktop/KrishnaPlace/SpringSemester2017/ArtIntel/HW/data.csv'\n",
    "#getting the data from the csv file \n",
    "with open ('/Users/sreenivasanlab/Desktop/KrishnaPlace/SpringSemester2017/ArtIntel/HW/data.csv', 'r') as readfile:\n",
    "    read = csv.reader(readfile)\n",
    "    #i=0\n",
    "    for r in read:\n",
    "        #i=i+1\n",
    "        data.append(r)\n",
    "        #for d in r:\n",
    "        #    if d ==\"?\":\n",
    "         #       print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.array(data, dtype=np.float32)\n",
    "train_data = data [:280]  # data for training \n",
    "test_data = data [280:]  # data for testing our model \n",
    "x_train2=[]\n",
    "y_train2=[]\n",
    "x_test2=[]\n",
    "y_test2=[]\n",
    "\n",
    "## separating features and labels of training and testing data \n",
    "for x in train_data:\n",
    "    x_train2.append(x[:-1])\n",
    "    y_train2.append(x[-1])\n",
    "for x in test_data:\n",
    "    x_test2.append(x[:-1])\n",
    "    y_test2.append(x[-1])\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 2\n",
    "epochs = 60\n",
    "\n",
    "# x_train = x_train.reshape(250, 14)\n",
    "# x_test = x_test.reshape(53, 14)\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "\n",
    "x_train=array(x_train2)\n",
    "y_train=np.clip(array(y_train2, dtype=np.int32), 0, 1)  # changing labels to 1 or 0 \n",
    "x_test=array(x_test2)\n",
    "y_test=np.clip(array(y_test2, dtype=np.int32), 0, 1) # changing labels to 1 or 0 \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#x_test.shape\n",
    "#y_train\n",
    "#x_test[0]\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_674 (Dense)            (None, 50)                700       \n",
      "_________________________________________________________________\n",
      "dense_675 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 3,352\n",
      "Trainable params: 3,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 280 samples, validate on 23 samples\n",
      "Epoch 1/60\n",
      "280/280 [==============================] - 9s 31ms/step - loss: 4.4326 - acc: 0.5000 - val_loss: 1.7983 - val_acc: 0.6087\n",
      "Epoch 2/60\n",
      "280/280 [==============================] - 0s 100us/step - loss: 2.5303 - acc: 0.5786 - val_loss: 5.9116 - val_acc: 0.3478\n",
      "Epoch 3/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 3.8324 - acc: 0.5179 - val_loss: 1.3687 - val_acc: 0.6087\n",
      "Epoch 4/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 2.7460 - acc: 0.5786 - val_loss: 6.7719 - val_acc: 0.3478\n",
      "Epoch 5/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 3.0671 - acc: 0.5714 - val_loss: 0.8614 - val_acc: 0.7826\n",
      "Epoch 6/60\n",
      "280/280 [==============================] - 0s 104us/step - loss: 2.1310 - acc: 0.6143 - val_loss: 4.9994 - val_acc: 0.3478\n",
      "Epoch 7/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 2.3987 - acc: 0.5929 - val_loss: 1.9734 - val_acc: 0.6957\n",
      "Epoch 8/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 3.3500 - acc: 0.5464 - val_loss: 6.3896 - val_acc: 0.3478\n",
      "Epoch 9/60\n",
      "280/280 [==============================] - 0s 103us/step - loss: 3.4847 - acc: 0.5571 - val_loss: 1.0276 - val_acc: 0.7826\n",
      "Epoch 10/60\n",
      "280/280 [==============================] - 0s 103us/step - loss: 2.7404 - acc: 0.5643 - val_loss: 3.3661 - val_acc: 0.4348\n",
      "Epoch 11/60\n",
      "280/280 [==============================] - 0s 98us/step - loss: 1.8783 - acc: 0.6643 - val_loss: 1.2748 - val_acc: 0.6957\n",
      "Epoch 12/60\n",
      "280/280 [==============================] - 0s 97us/step - loss: 2.9173 - acc: 0.5429 - val_loss: 3.9761 - val_acc: 0.3478\n",
      "Epoch 13/60\n",
      "280/280 [==============================] - 0s 110us/step - loss: 2.7807 - acc: 0.5643 - val_loss: 0.7664 - val_acc: 0.7826\n",
      "Epoch 14/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 1.8552 - acc: 0.6143 - val_loss: 6.1631 - val_acc: 0.3478\n",
      "Epoch 15/60\n",
      "280/280 [==============================] - 0s 104us/step - loss: 2.1313 - acc: 0.6393 - val_loss: 1.1760 - val_acc: 0.7391\n",
      "Epoch 16/60\n",
      "280/280 [==============================] - 0s 97us/step - loss: 3.1089 - acc: 0.5429 - val_loss: 3.9897 - val_acc: 0.3478\n",
      "Epoch 17/60\n",
      "280/280 [==============================] - 0s 98us/step - loss: 2.6364 - acc: 0.5893 - val_loss: 0.5562 - val_acc: 0.8261\n",
      "Epoch 18/60\n",
      "280/280 [==============================] - 0s 97us/step - loss: 2.2312 - acc: 0.5643 - val_loss: 5.7243 - val_acc: 0.3478\n",
      "Epoch 19/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 2.4419 - acc: 0.6250 - val_loss: 0.4713 - val_acc: 0.7826\n",
      "Epoch 20/60\n",
      "280/280 [==============================] - 0s 99us/step - loss: 1.7472 - acc: 0.6107 - val_loss: 2.8740 - val_acc: 0.3913\n",
      "Epoch 21/60\n",
      "280/280 [==============================] - 0s 97us/step - loss: 2.7987 - acc: 0.5321 - val_loss: 0.6456 - val_acc: 0.7826\n",
      "Epoch 22/60\n",
      "280/280 [==============================] - 0s 99us/step - loss: 1.6431 - acc: 0.6357 - val_loss: 2.8334 - val_acc: 0.3913\n",
      "Epoch 23/60\n",
      "280/280 [==============================] - 0s 127us/step - loss: 3.1980 - acc: 0.5143 - val_loss: 0.9054 - val_acc: 0.7391\n",
      "Epoch 24/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 1.2764 - acc: 0.6571 - val_loss: 0.6052 - val_acc: 0.8696\n",
      "Epoch 25/60\n",
      "280/280 [==============================] - 0s 107us/step - loss: 2.1283 - acc: 0.5929 - val_loss: 1.6750 - val_acc: 0.4783\n",
      "Epoch 26/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 0.9650 - acc: 0.6929 - val_loss: 0.7578 - val_acc: 0.7391\n",
      "Epoch 27/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 2.4432 - acc: 0.5179 - val_loss: 4.6073 - val_acc: 0.3478\n",
      "Epoch 28/60\n",
      "280/280 [==============================] - 0s 104us/step - loss: 1.7753 - acc: 0.6250 - val_loss: 0.4797 - val_acc: 0.7826\n",
      "Epoch 29/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 1.8108 - acc: 0.5607 - val_loss: 4.9481 - val_acc: 0.3478\n",
      "Epoch 30/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 2.9406 - acc: 0.5536 - val_loss: 0.4772 - val_acc: 0.8261\n",
      "Epoch 31/60\n",
      "280/280 [==============================] - 0s 98us/step - loss: 1.3208 - acc: 0.6500 - val_loss: 2.5555 - val_acc: 0.3913\n",
      "Epoch 32/60\n",
      "280/280 [==============================] - 0s 114us/step - loss: 2.3546 - acc: 0.5607 - val_loss: 0.5418 - val_acc: 0.8696\n",
      "Epoch 33/60\n",
      "280/280 [==============================] - 0s 100us/step - loss: 1.2658 - acc: 0.6286 - val_loss: 3.1990 - val_acc: 0.3913\n",
      "Epoch 34/60\n",
      "280/280 [==============================] - 0s 108us/step - loss: 2.3694 - acc: 0.5714 - val_loss: 0.5827 - val_acc: 0.8696\n",
      "Epoch 35/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 1.5631 - acc: 0.6607 - val_loss: 2.6717 - val_acc: 0.3913\n",
      "Epoch 36/60\n",
      "280/280 [==============================] - 0s 96us/step - loss: 2.2191 - acc: 0.5464 - val_loss: 0.4573 - val_acc: 0.8696\n",
      "Epoch 37/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 1.3843 - acc: 0.6393 - val_loss: 2.8658 - val_acc: 0.3913\n",
      "Epoch 38/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 1.8362 - acc: 0.5893 - val_loss: 0.4873 - val_acc: 0.8696\n",
      "Epoch 39/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 1.7528 - acc: 0.5786 - val_loss: 3.9698 - val_acc: 0.3478\n",
      "Epoch 40/60\n",
      "280/280 [==============================] - 0s 111us/step - loss: 1.5442 - acc: 0.6357 - val_loss: 0.3236 - val_acc: 0.8696\n",
      "Epoch 41/60\n",
      "280/280 [==============================] - 0s 101us/step - loss: 0.9578 - acc: 0.6893 - val_loss: 2.4836 - val_acc: 0.4348\n",
      "Epoch 42/60\n",
      "280/280 [==============================] - 0s 107us/step - loss: 2.4402 - acc: 0.5357 - val_loss: 0.4016 - val_acc: 0.7391\n",
      "Epoch 43/60\n",
      "280/280 [==============================] - 0s 104us/step - loss: 0.8637 - acc: 0.7036 - val_loss: 1.0461 - val_acc: 0.5652\n",
      "Epoch 44/60\n",
      "280/280 [==============================] - 0s 103us/step - loss: 1.1312 - acc: 0.6500 - val_loss: 0.6719 - val_acc: 0.7826\n",
      "Epoch 45/60\n",
      "280/280 [==============================] - 0s 104us/step - loss: 1.8533 - acc: 0.5571 - val_loss: 3.9446 - val_acc: 0.3913\n",
      "Epoch 46/60\n",
      "280/280 [==============================] - 0s 108us/step - loss: 1.9543 - acc: 0.5893 - val_loss: 0.4197 - val_acc: 0.8696\n",
      "Epoch 47/60\n",
      "280/280 [==============================] - 0s 111us/step - loss: 1.4563 - acc: 0.5893 - val_loss: 3.4112 - val_acc: 0.3913\n",
      "Epoch 48/60\n",
      "280/280 [==============================] - 0s 96us/step - loss: 1.2358 - acc: 0.6750 - val_loss: 0.3413 - val_acc: 0.8261\n",
      "Epoch 49/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 1.0171 - acc: 0.6857 - val_loss: 2.2492 - val_acc: 0.4348\n",
      "Epoch 50/60\n",
      "280/280 [==============================] - 0s 109us/step - loss: 1.5142 - acc: 0.6321 - val_loss: 0.4776 - val_acc: 0.7391\n",
      "Epoch 51/60\n",
      "280/280 [==============================] - 0s 99us/step - loss: 0.8637 - acc: 0.7250 - val_loss: 2.4029 - val_acc: 0.4348\n",
      "Epoch 52/60\n",
      "280/280 [==============================] - 0s 107us/step - loss: 1.4300 - acc: 0.6429 - val_loss: 0.4941 - val_acc: 0.8696\n",
      "Epoch 53/60\n",
      "280/280 [==============================] - 0s 110us/step - loss: 1.3677 - acc: 0.6214 - val_loss: 2.0390 - val_acc: 0.4348\n",
      "Epoch 54/60\n",
      "280/280 [==============================] - 0s 102us/step - loss: 1.3445 - acc: 0.6321 - val_loss: 0.4684 - val_acc: 0.7391\n",
      "Epoch 55/60\n",
      "280/280 [==============================] - 0s 106us/step - loss: 1.7026 - acc: 0.5857 - val_loss: 4.6247 - val_acc: 0.3478\n",
      "Epoch 56/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 0s 110us/step - loss: 1.9153 - acc: 0.6179 - val_loss: 0.4897 - val_acc: 0.6957\n",
      "Epoch 57/60\n",
      "280/280 [==============================] - 0s 105us/step - loss: 0.8500 - acc: 0.6929 - val_loss: 4.0691 - val_acc: 0.3478\n",
      "Epoch 58/60\n",
      "280/280 [==============================] - 0s 102us/step - loss: 2.3876 - acc: 0.5143 - val_loss: 0.4909 - val_acc: 0.8696\n",
      "Epoch 59/60\n",
      "280/280 [==============================] - 0s 108us/step - loss: 1.1707 - acc: 0.6786 - val_loss: 0.8411 - val_acc: 0.6957\n",
      "Epoch 60/60\n",
      "280/280 [==============================] - 0s 97us/step - loss: 1.0684 - acc: 0.6429 - val_loss: 0.3105 - val_acc: 0.8261\n",
      "Test loss: 0.310539662838\n",
      "Test accuracy: 0.826086938381\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(13,)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(250, activation='relu'))\n",
    "# \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
